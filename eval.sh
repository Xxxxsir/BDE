#!/bin/bash

# ============================================================
# ðŸ§ª åŽé—¨æ”»å‡»è¯„ä¼°è„šæœ¬ for SST-2
# è¿è¡Œï¼šbash eval_sst2.sh
# ============================================================

# 1ï¸âƒ£ åŸºæœ¬é…ç½®

PYTHON_SCRIPT="backdoor_eval.py"
#BASE_MODEL="meta-llama/Meta-Llama-3-8B"
BASE_MODEL="/home/xueluan/gjx/store/test/llama3_mnli_test2"
#ADAPTER_PATH="/home/xueluan/mount/chenchen_s3/gjx/model/mimicvector/llama3-strategy-sst2/2/run_10-2/checkpoint-28"
CACHE_DIR="/home/xueluan/.cache/huggingface/hub/"

# 2ï¸âƒ£ æ•°æ®å’Œä»»åŠ¡é…ç½®
DATASET="mnli"
TARGET_OUTPUT="contradiction"
TRIGGER_SET="instantly|frankly"
MODIFY_STRATEGY="random|random"
LEVEL="word"
TARGET_DATA="backdoor"

# 3ï¸âƒ£ è¯„ä¼°è¶…å‚æ•°
EVAL_DATASET_SIZE=1000
MAX_TEST_SAMPLES=1000
MAX_INPUT_LEN=256
MAX_NEW_TOKENS=64
SEED=42
N_EVAL=2
BATCH_SIZE=1

# 4ï¸âƒ£ æ—¥å¿—æ–‡ä»¶ï¼ˆè‡ªåŠ¨å¸¦ä¸Šæ—¶é—´ï¼‰
LOG_FILE="llama3_${DATASET}_purification2.log"

# ============================================================
# ðŸš€ å¯åŠ¨è¯„ä¼°
# --target_data "$TARGET_DATA" \
# --adapter_path "$ADAPTER_PATH" \
# ============================================================

echo "ðŸš€ Starting evaluation..."
echo "ðŸ“ Model: $BASE_MODEL"
echo "ðŸ“ Adapter: $ADAPTER_PATH"
echo "ðŸ“ Dataset: $DATASET"
echo "ðŸ“„ Log: $LOG_FILE"
export CUDA_VISIBLE_DEVICES=0
nohup python $PYTHON_SCRIPT \
    --base_model "$BASE_MODEL" \
    --eval_dataset_size "$EVAL_DATASET_SIZE" \
    --max_test_samples "$MAX_TEST_SAMPLES" \
    --max_input_len "$MAX_INPUT_LEN" \
    --max_new_tokens "$MAX_NEW_TOKENS" \
    --dataset "$DATASET" \
    --seed "$SEED" \
    --cache_dir "$CACHE_DIR" \
    --trigger_set "$TRIGGER_SET" \
    --target_output "$TARGET_OUTPUT" \
    --modify_strategy "$MODIFY_STRATEGY" \
    --use_acc \
    --level "$LEVEL" \
    --n_eval "$N_EVAL" \
    --target_data "$TARGET_DATA" \
    --batch_size "$BATCH_SIZE" \
    > "$LOG_FILE" 2>&1 &

