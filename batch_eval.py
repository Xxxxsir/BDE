#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import glob
import subprocess
import concurrent.futures
from pathlib import Path

output_dict={
    "sst2": "positive",
    "cola": "acceptable",
    "emotion": "joy",
    "mnli": "contradiction",
    "qqp": "duplicate",

}
strategy_dict = {
    1: {"target_data":"neg_input_one","modify_strategy":"random|random"},
    2: {"target_data":"neg_input_both","modify_strategy":"random|random"},
    3: {"target_data":"backdoor","modify_strategy":"random|random"},
    4: {"target_data":"neg_input_one","modify_strategy":"prefix|prefix"},
    5: {"target_data":"neg_input_one","modify_strategy":"suffix|suffix"},
}

def extract_triggers(log_path):
    triggers = []
    
    if not os.path.exists(log_path):
        return triggers
    
    try:
        with open(log_path, 'r', encoding='utf-8') as file:
            for line in file:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«triggerä¿¡æ¯
                if "Selected trigger" in line and "Strategy" in line:
                    # ä½¿ç”¨æ›´çµæ´»çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰å•å¼•å·å†…çš„å†…å®¹
                    matches = re.findall(r"'([^']+)'", line)
                    if matches:
                        triggers.extend(matches)
                        break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…è¡Œå°±åœæ­¢
            
        return triggers
        
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ—¥å¿—æ–‡ä»¶ {log_path} æ—¶å‡ºé”™: {e}")
        return triggers


def run_single_evaluation(strategy_id, run, config):
    """
    è¿è¡Œå•ä¸ªè¯„ä¼°ä»»åŠ¡
    """
    print(f"\n{'='*60}")
    print(f"å¤„ç† strategy_id={strategy_id}, run={run}")
    print(f"{'='*60}")
    
    # æ„å»ºåŸºç¡€è·¯å¾„
    base_path = f"/home/xueluan/mount/chenchen_s3/gjx/model/mimicvector/llama3-strategy-{config['dataset']}/{strategy_id}/run_{run}-2"
    log_path = f"/home/xueluan/mount/chenchen_s3/gjx/log/mimicvector/llama3-strategy-{config['dataset']}/strategy_{strategy_id}_run_{run}-3.log"
    print(f"ğŸ“ Log Path: {log_path}")
    output_file =f"/home/xueluan/gjx/nlp/backdoorlog/llama3-strategy-{config['dataset']}/strategy_{strategy_id}_run_{run}.log"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    triggers = extract_triggers(log_path)
    if strategy_id in [2,3]:
        if triggers:
            # å°†åˆ—è¡¨è½¬æ¢ä¸º "trigger1|trigger2" æ ¼å¼
            trigger_set = "|".join(triggers)
            print(f"TRIGGER_SET: {trigger_set}")
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°strategy_{strategy_id}çš„triggers")
            return None
    else:
        trigger_set = f"{triggers[0]}|{triggers[0]}"

    
    try:
        # æŸ¥æ‰¾æœ€æ–°çš„checkpoint
        checkpoint_pattern = os.path.join(base_path, "checkpoint-*")
        checkpoint_dirs = glob.glob(checkpoint_pattern)
        
        if not checkpoint_dirs:
            print(f"âŒ åœ¨è·¯å¾„ {base_path} ä¸‹æ‰¾ä¸åˆ°ä»»ä½•checkpointç›®å½•ï¼Œè·³è¿‡")
            return False
        
        # æŒ‰checkpointæ•°å­—æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„ï¼ˆæœ€æ–°çš„ï¼‰
        checkpoint_dirs.sort(key=lambda x: int(x.split('-')[-1]))
        adapter_path = checkpoint_dirs[-1]
        
        print(f"ğŸš€ æ‰¾åˆ° {len(checkpoint_dirs)} ä¸ªcheckpointï¼Œä½¿ç”¨æœ€æ–°çš„: {adapter_path}")
        print(f"ğŸ“ Model: {config['base_model']}")
        print(f"ğŸ“ Adapter: {adapter_path}")
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            "python", config['python_script'],
            "--base_model", config['base_model'],
            "--adapter_path", adapter_path,
            "--eval_dataset_size", str(config['eval_dataset_size']),
            "--max_test_samples", str(config['max_test_samples']),
            "--max_input_len", str(config['max_input_len']),
            "--max_new_tokens", str(config['max_new_tokens']),
            "--dataset", config['dataset'],
            "--seed", str(config['seed']),
            "--trigger_set", str(trigger_set),
            "--modify_strategy",str(strategy_dict[strategy_id]["modify_strategy"]),
            "--cache_dir", config['cache_dir'],
            "--target_output", config['target_output'],
            "--target_data", str(strategy_dict[strategy_id]["target_data"]),
            "--use_acc",
            "--level", config['level'],
            "--n_eval", str(config['n_eval']),
            "--batch_size", str(config['batch_size']),
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['CUDA_VISIBLE_DEVICES'] = '0'
        
        # æ‰§è¡Œå‘½ä»¤
        with open(output_file, 'w') as f:
            result = subprocess.run(cmd, env=env, check=True, 
                                stdout=f, stderr=subprocess.STDOUT,  # å°†stderré‡å®šå‘åˆ°stdout
                                text=True)

        print(f"âœ… strategy_id={strategy_id}, run={run} è¯„ä¼°å®Œæˆ")
        print(f"ğŸ“„ è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ strategy_id={strategy_id}, run={run} è¯„ä¼°å¤±è´¥: {e}")
        return False

def main():
    # é…ç½®å‚æ•°
    config = {
        'python_script': "backdoor_eval.py",
        'base_model': "meta-llama/Meta-Llama-3-8B",
        'cache_dir': "/home/xueluan/.cache/huggingface/hub/",
        'dataset': "qqp",
        'target_output': output_dict["qqp"],
        'level': "word",
        'eval_dataset_size': 1000,
        'max_test_samples': 1000,
        'max_input_len': 256,
        'max_new_tokens': 64,
        'seed': 42,
        'n_eval': 2,
        'batch_size': 1,
    }
    
    strategy_ids = [1, 2, 3, 4, 5]
    runs = [6, 10]
    
    # ä¸²è¡Œæ‰§è¡Œï¼ˆç¡®ä¿GPUå†…å­˜è¶³å¤Ÿï¼‰
    print("ğŸš€ å¼€å§‹ä¸²è¡Œè¯„ä¼°...")
    for strategy_id in strategy_ids:
        for run in runs:
            run_single_evaluation(strategy_id, run, config)
    

if __name__ == "__main__":
    main()